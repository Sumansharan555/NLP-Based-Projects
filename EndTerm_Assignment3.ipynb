{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE9a7fvB2gow"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 3: Apply NLP techniques like Part-of-Speech tagging, Named Entity Recognition (NER), and dependency parsing for text understanding. Perform text classification, sentiment analysis, and topic modeling to extract insights from unstructured text."
      ],
      "metadata": {
        "id": "H9RabIK24Fda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-of-Speech Tagging, NER, Dependency Parsing"
      ],
      "metadata": {
        "id": "K8ZmJ0fCRYvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "# POS Tagging\n",
        "print([(token.text, token.pos_) for token in doc])\n",
        "\n",
        "# Named Entity Recognition\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])\n",
        "\n",
        "# Dependency Parsing\n",
        "print([(token.text, token.dep_, token.head.text) for token in doc])"
      ],
      "metadata": {
        "id": "1mWGxE2X4GBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815d92b7-a113-461d-fa88-3df8b6b68ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Apple', 'PROPN'), ('is', 'AUX'), ('looking', 'VERB'), ('at', 'ADP'), ('buying', 'VERB'), ('U.K.', 'PROPN'), ('startup', 'VERB'), ('for', 'ADP'), ('$', 'SYM'), ('1', 'NUM'), ('billion', 'NUM')]\n",
            "[('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]\n",
            "[('Apple', 'nsubj', 'looking'), ('is', 'aux', 'looking'), ('looking', 'ROOT', 'looking'), ('at', 'prep', 'looking'), ('buying', 'pcomp', 'at'), ('U.K.', 'nsubj', 'startup'), ('startup', 'ccomp', 'buying'), ('for', 'prep', 'startup'), ('$', 'quantmod', 'billion'), ('1', 'compound', 'billion'), ('billion', 'pobj', 'for')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Classification & Sentiment Analysis"
      ],
      "metadata": {
        "id": "zb-wWBIaRi6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "sample = \"I absolutely loved this movie, it was fantastic!\"\n",
        "blob = TextBlob(sample)\n",
        "print(\"Sentiment polarity:\", blob.sentiment.polarity)  # >0 positive, <0 negative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssrwl18QRJ47",
        "outputId": "b25027d2-3723-45c7-8a27-014e6a2ee2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment polarity: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "texts = [\"Win money now\", \"Hello friend\"]\n",
        "labels = [1, 0]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X, labels)\n",
        "\n",
        "print(model.predict(vectorizer.transform([\"Win a prize\"])))\n"
      ],
      "metadata": {
        "id": "0cRtObdeSajb",
        "outputId": "e41df74c-87f4-4e0b-9d2c-c56b0e6411b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic Modeling (LDA)"
      ],
      "metadata": {
        "id": "Am8mPWSaRwo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Define a list of sample texts for topic modeling\n",
        "texts = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Never jump over the fence in the dark.\",\n",
        "    \"Dogs and cats are common pets. Cats are independent animals.\",\n",
        "    \"Topic modeling helps in understanding the main themes in a collection of documents.\",\n",
        "    \"Natural language processing is a field of artificial intelligence.\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=2, random_state=42)\n",
        "lda.fit(X)\n",
        "\n",
        "for idx, topic in enumerate(lda.components_):\n",
        "    print(f\"Topic {idx}:\",\n",
        "          [vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-5:]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXrX9V_4Rr7a",
        "outputId": "d66dc472-0293-469a-868f-fd924eead639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: ['main', 'modeling', 'themes', 'topic', 'understanding']\n",
            "Topic 1: ['pets', 'independent', 'common', 'dogs', 'cats']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kts0tDpYR0w6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}